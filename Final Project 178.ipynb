{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training data\n",
    "X = np.genfromtxt(\"data/X_train.txt\", delimiter=None) #load the data\n",
    "Y= np.genfromtxt(\"data/Y_train.txt\", delimiter=None) #load the data\n",
    "\n",
    "#and the test features\n",
    "Xte= np.genfromtxt(\"data/X_test.txt\", delimiter=None) #load the data\n",
    "\n",
    "Xtr,Xva,Ytr,Yva = ml.splitData(X,Y); # Default is 80% training/20% validation\n",
    "Xtr, Ytr = ml.shuffleData(Xtr, Ytr)\n",
    "\n",
    "#Taking a subset for testing (get rid of this later)\n",
    "#Xtr, Ytr = Xtr[:4000], Ytr[:4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3b05a08d3f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### Rescale Training data (Xtr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create polynomial features up to \"degree\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mXtrP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpoly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Rescale the data matrix so that the features have similar ranges / variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CS 178/final project/mltools/transforms.py\u001b[0m in \u001b[0;36mfpoly\u001b[0;34m(X, degree, bias)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mpowers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpowers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "#polynomial degree\n",
    "degree = 0.5\n",
    "\n",
    "### Rescale Training data (Xtr)\n",
    "# Create polynomial features up to \"degree\"\n",
    "XtrP = ml.transforms.fpoly(Xtr, degree, bias=False)\n",
    "\n",
    "# Rescale the data matrix so that the features have similar ranges / variance\n",
    "XtrP,params = ml.transforms.rescale(XtrP) # \"params\" returns the transformation parameters (shift & scale)\n",
    "\n",
    "###Rescale test data (Xte)\n",
    "#Apply the same polynomial expansion & scaling transformation as XtrP\n",
    "XteP, _ = ml.transforms.rescale(ml.transforms.fpoly(Xte,degree, False),params)\n",
    "\n",
    "### Rescale Validation Data (Xva)\n",
    "#Apply the same polynomial expansion & scaling transformation as XtrP\n",
    "XvaP, _ =  ml.transforms.rescale(ml.transforms.fpoly(Xva,degree, False),params)\n",
    "\n",
    "#check shapes\n",
    "print(XtrP.shape, XvaP.shape, XteP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deejayslay/Documents/CS 178/final project/mltools/base.py:96: RuntimeWarning: divide by zero encountered in log\n",
      "  return - np.mean( np.log( P[ np.arange(M), Y ] ) ) # evaluate\n",
      "/Users/deejayslay/Documents/CS 178/final project/mltools/linearC.py:134: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  done = (it > stopIter) or ( (it>1) and (abs(Jsur[-1]-Jsur[-2])<stopTol) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67867453 0.32132547]\n",
      " [0.56008662 0.43991338]\n",
      " [0.73189031 0.26810969]\n",
      " [0.80349101 0.19650899]\n",
      " [0.76024431 0.23975569]]\n",
      "      Train AUC: 0.6602\n",
      " Validation AUC: 0.6569\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the scaled feature matrix:\n",
    "learner = ml.linearC.linearClassify()\n",
    "learner.train(XtrP, Ytr, reg=0.1, initStep=0.01, stopTol=1e-6, stopIter=100)\n",
    "\n",
    "probs = learner.predictSoft(XteP)\n",
    "print(probs[:5])\n",
    "\n",
    "#Use XtrP and XvaP\n",
    "print(\"{0:>15}: {1:.4f}\".format('Train AUC',learner.auc(XtrP, Ytr)))\n",
    "print(\"{0:>15}: {1:.4f}\".format('Validation AUC', learner.auc(XvaP, Yva)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the submission text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data for submission by taking the P(Y=1) column from probs and just add a running index as the first column.\n",
    "Y_sub = np.vstack([np.arange(XteP.shape[0]), probs[:, 1]]).T\n",
    "\n",
    "# We specify the header (ID, Prob1) and also specify the comments as '' so the header won't be commented out with\n",
    "# the # sign.\n",
    "np.savetxt('data/Y_sub.txt', Y_sub, '%d, %.5f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
